---
layout: page
title: My work
modified: 2014-07-31T13:23:02.362000-04:00
excerpt: "My work"
embedded: <iframe src='//padlet.com/embed/vv562ia8ablc' frameborder='0' width='100%' height='350px' style='padding:0;margin:0;border:none'></iframe>
---

## Area of interests

Robotics, Computer Vision, Visual Servoing, Machine Learning.

## What I am doing now

I am currently a R&D Robotics Engineer working in the [Lagadic](http://www.irisa.fr/lagadic/) group at [INRIA](http://www.inria.fr/en/) in Rennes.


### My Lab
Research activities of the [Lagadic](http://www.irisa.fr/lagadic/) team deals with robot vision, visual servoing, real time visual tracking and SLAM for applications in localization, manipulation, navigation, medical robotics and augmented reality. Visual servoing consists in using the information provided
by a vision sensor to control the movements of a dynamic system. Such systems are usually robot arms, or mobile robots, but can also be virtual robots, or even a virtual camera.

### My job

*  The aim of the job is to adapt the visual servoing techniques developed in the EPI Lagadic on the robot Humanoid [Romeo](http://projetromeo.com/) ([Aldebaran](http://www.aldebaran.com/en)). The objective is to control the Romeo using its own sensors (mainly cameras), for achieving desired positions and for object grasping and manipulation.

<iframe width="90%" height="480" src="//www.youtube.com/embed/kz1Ob0Ks554" frameborder="2" allowfullscreen></iframe>

* In the lab we needed a simulation environment to test and debug our algorithm with no risk of damaging the real robots and to have the possibility to create different virtual situations. We wanted a generic environment to be used for the robots in the lab (for instance the Viper 850s, the Pioneer P3-DX robot from Adept and quadropters) and for robots we do not have. 




<iframe width="853" height="480" src="//www.youtube.com/embed/SZxp6BJgBUg" frameborder="0" allowfullscreen></iframe>
